{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Classification problem using Keras\n",
    "\n",
    "We use the data available for the dide-effects of an experimental drug tested on patients to make predictions on new patients who are yet to be given this drug.\n",
    "\n",
    "\n",
    "### Preprocessing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dummy dataset:\n",
    "\n",
    "* An experimental drug was tested on patients aged between 13 to 100.\n",
    "* The trial had 2100 patients. First half were under 65 years and second half were 65 years old and above.\n",
    "* 95% of patients in the second group experienced side-effects\n",
    "* 95% of patients in the first group experienced no side-effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []\n",
    "\n",
    "for i in range(50):\n",
    "    firstGroup = randint(13, 64)\n",
    "    train_samples.append(firstGroup)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    secondGroup = randint(65, 100)\n",
    "    train_samples.append(secondGroup)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "for i in range(1000):\n",
    "    firstGroup = randint(13, 64)\n",
    "    train_samples.append(firstGroup)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    secondGroup = randint(65, 100)\n",
    "    train_samples.append(secondGroup)\n",
    "    train_labels.append(1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33,\n",
       " 74,\n",
       " 49,\n",
       " 71,\n",
       " 14,\n",
       " 83,\n",
       " 30,\n",
       " 93,\n",
       " 13,\n",
       " 90,\n",
       " 30,\n",
       " 76,\n",
       " 32,\n",
       " 75,\n",
       " 21,\n",
       " 93,\n",
       " 40,\n",
       " 90,\n",
       " 16,\n",
       " 80,\n",
       " 51,\n",
       " 98,\n",
       " 52,\n",
       " 90,\n",
       " 41,\n",
       " 99,\n",
       " 63,\n",
       " 69,\n",
       " 14,\n",
       " 95,\n",
       " 50,\n",
       " 81,\n",
       " 44,\n",
       " 78,\n",
       " 49,\n",
       " 65,\n",
       " 60,\n",
       " 89,\n",
       " 17,\n",
       " 70,\n",
       " 34,\n",
       " 72,\n",
       " 51,\n",
       " 93,\n",
       " 54,\n",
       " 91,\n",
       " 32,\n",
       " 100,\n",
       " 30,\n",
       " 82,\n",
       " 27,\n",
       " 91,\n",
       " 36,\n",
       " 89,\n",
       " 29,\n",
       " 91,\n",
       " 48,\n",
       " 91,\n",
       " 16,\n",
       " 92,\n",
       " 37,\n",
       " 87,\n",
       " 62,\n",
       " 73,\n",
       " 47,\n",
       " 88,\n",
       " 16,\n",
       " 67,\n",
       " 21,\n",
       " 76,\n",
       " 43,\n",
       " 93,\n",
       " 54,\n",
       " 77,\n",
       " 26,\n",
       " 85,\n",
       " 25,\n",
       " 98,\n",
       " 33,\n",
       " 66,\n",
       " 49,\n",
       " 90,\n",
       " 39,\n",
       " 71,\n",
       " 43,\n",
       " 87,\n",
       " 62,\n",
       " 78,\n",
       " 60,\n",
       " 81,\n",
       " 23,\n",
       " 65,\n",
       " 43,\n",
       " 71,\n",
       " 54,\n",
       " 79,\n",
       " 53,\n",
       " 90,\n",
       " 33,\n",
       " 97,\n",
       " 35,\n",
       " 77,\n",
       " 36,\n",
       " 76,\n",
       " 13,\n",
       " 88,\n",
       " 55,\n",
       " 81,\n",
       " 57,\n",
       " 82,\n",
       " 54,\n",
       " 90,\n",
       " 61,\n",
       " 97,\n",
       " 46,\n",
       " 79,\n",
       " 18,\n",
       " 89,\n",
       " 56,\n",
       " 91,\n",
       " 32,\n",
       " 92,\n",
       " 50,\n",
       " 90,\n",
       " 39,\n",
       " 65,\n",
       " 58,\n",
       " 94,\n",
       " 31,\n",
       " 95,\n",
       " 45,\n",
       " 94,\n",
       " 17,\n",
       " 89,\n",
       " 30,\n",
       " 66,\n",
       " 34,\n",
       " 76,\n",
       " 21,\n",
       " 81,\n",
       " 35,\n",
       " 100,\n",
       " 64,\n",
       " 81,\n",
       " 20,\n",
       " 85,\n",
       " 29,\n",
       " 87,\n",
       " 35,\n",
       " 96,\n",
       " 28,\n",
       " 98,\n",
       " 38,\n",
       " 87,\n",
       " 52,\n",
       " 73,\n",
       " 64,\n",
       " 70,\n",
       " 49,\n",
       " 87,\n",
       " 31,\n",
       " 94,\n",
       " 52,\n",
       " 66,\n",
       " 45,\n",
       " 79,\n",
       " 46,\n",
       " 83,\n",
       " 59,\n",
       " 65,\n",
       " 61,\n",
       " 78,\n",
       " 17,\n",
       " 77,\n",
       " 27,\n",
       " 65,\n",
       " 47,\n",
       " 82,\n",
       " 13,\n",
       " 74,\n",
       " 19,\n",
       " 86,\n",
       " 40,\n",
       " 78,\n",
       " 52,\n",
       " 66,\n",
       " 14,\n",
       " 97,\n",
       " 24,\n",
       " 87,\n",
       " 62,\n",
       " 66,\n",
       " 33,\n",
       " 87,\n",
       " 17,\n",
       " 79,\n",
       " 49,\n",
       " 70,\n",
       " 31,\n",
       " 74,\n",
       " 35,\n",
       " 77,\n",
       " 63,\n",
       " 80,\n",
       " 44,\n",
       " 77,\n",
       " 50,\n",
       " 69,\n",
       " 58,\n",
       " 87,\n",
       " 35,\n",
       " 81,\n",
       " 47,\n",
       " 99,\n",
       " 42,\n",
       " 65,\n",
       " 46,\n",
       " 68,\n",
       " 19,\n",
       " 89,\n",
       " 60,\n",
       " 83,\n",
       " 14,\n",
       " 79,\n",
       " 31,\n",
       " 85,\n",
       " 45,\n",
       " 96,\n",
       " 44,\n",
       " 87,\n",
       " 48,\n",
       " 90,\n",
       " 59,\n",
       " 66,\n",
       " 53,\n",
       " 71,\n",
       " 54,\n",
       " 83,\n",
       " 28,\n",
       " 85,\n",
       " 49,\n",
       " 93,\n",
       " 51,\n",
       " 73,\n",
       " 49,\n",
       " 99,\n",
       " 25,\n",
       " 85,\n",
       " 14,\n",
       " 67,\n",
       " 53,\n",
       " 68,\n",
       " 22,\n",
       " 86,\n",
       " 38,\n",
       " 98,\n",
       " 60,\n",
       " 92,\n",
       " 61,\n",
       " 92,\n",
       " 27,\n",
       " 94,\n",
       " 54,\n",
       " 88,\n",
       " 19,\n",
       " 90,\n",
       " 44,\n",
       " 75,\n",
       " 61,\n",
       " 100,\n",
       " 54,\n",
       " 71,\n",
       " 22,\n",
       " 94,\n",
       " 44,\n",
       " 79,\n",
       " 53,\n",
       " 66,\n",
       " 27,\n",
       " 71,\n",
       " 57,\n",
       " 65,\n",
       " 36,\n",
       " 77,\n",
       " 47,\n",
       " 92,\n",
       " 43,\n",
       " 82,\n",
       " 38,\n",
       " 73,\n",
       " 45,\n",
       " 83,\n",
       " 19,\n",
       " 95,\n",
       " 37,\n",
       " 70,\n",
       " 44,\n",
       " 79,\n",
       " 52,\n",
       " 86,\n",
       " 16,\n",
       " 79,\n",
       " 56,\n",
       " 77,\n",
       " 62,\n",
       " 100,\n",
       " 24,\n",
       " 88,\n",
       " 27,\n",
       " 69,\n",
       " 61,\n",
       " 78,\n",
       " 33,\n",
       " 71,\n",
       " 36,\n",
       " 75,\n",
       " 60,\n",
       " 87,\n",
       " 14,\n",
       " 97,\n",
       " 30,\n",
       " 87,\n",
       " 21,\n",
       " 73,\n",
       " 22,\n",
       " 70,\n",
       " 35,\n",
       " 71,\n",
       " 54,\n",
       " 93,\n",
       " 28,\n",
       " 87,\n",
       " 24,\n",
       " 79,\n",
       " 24,\n",
       " 96,\n",
       " 38,\n",
       " 100,\n",
       " 55,\n",
       " 95,\n",
       " 24,\n",
       " 93,\n",
       " 16,\n",
       " 90,\n",
       " 33,\n",
       " 73,\n",
       " 62,\n",
       " 71,\n",
       " 64,\n",
       " 70,\n",
       " 18,\n",
       " 72,\n",
       " 41,\n",
       " 75,\n",
       " 17,\n",
       " 78,\n",
       " 21,\n",
       " 98,\n",
       " 23,\n",
       " 93,\n",
       " 47,\n",
       " 76,\n",
       " 41,\n",
       " 89,\n",
       " 48,\n",
       " 96,\n",
       " 20,\n",
       " 96,\n",
       " 41,\n",
       " 95,\n",
       " 22,\n",
       " 68,\n",
       " 55,\n",
       " 98,\n",
       " 32,\n",
       " 77,\n",
       " 29,\n",
       " 72,\n",
       " 18,\n",
       " 100,\n",
       " 42,\n",
       " 72,\n",
       " 15,\n",
       " 77,\n",
       " 51,\n",
       " 93,\n",
       " 63,\n",
       " 98,\n",
       " 56,\n",
       " 97,\n",
       " 24,\n",
       " 77,\n",
       " 57,\n",
       " 94,\n",
       " 29,\n",
       " 69,\n",
       " 15,\n",
       " 91,\n",
       " 15,\n",
       " 88,\n",
       " 58,\n",
       " 66,\n",
       " 36,\n",
       " 70,\n",
       " 13,\n",
       " 85,\n",
       " 23,\n",
       " 85,\n",
       " 57,\n",
       " 69,\n",
       " 41,\n",
       " 86,\n",
       " 55,\n",
       " 73,\n",
       " 36,\n",
       " 68,\n",
       " 32,\n",
       " 74,\n",
       " 52,\n",
       " 67,\n",
       " 63,\n",
       " 96,\n",
       " 41,\n",
       " 90,\n",
       " 15,\n",
       " 97,\n",
       " 37,\n",
       " 76,\n",
       " 18,\n",
       " 90,\n",
       " 22,\n",
       " 98,\n",
       " 19,\n",
       " 95,\n",
       " 42,\n",
       " 91,\n",
       " 31,\n",
       " 94,\n",
       " 24,\n",
       " 70,\n",
       " 23,\n",
       " 92,\n",
       " 33,\n",
       " 86,\n",
       " 40,\n",
       " 99,\n",
       " 39,\n",
       " 68,\n",
       " 33,\n",
       " 94,\n",
       " 32,\n",
       " 98,\n",
       " 36,\n",
       " 98,\n",
       " 34,\n",
       " 76,\n",
       " 47,\n",
       " 70,\n",
       " 37,\n",
       " 75,\n",
       " 24,\n",
       " 69,\n",
       " 13,\n",
       " 66,\n",
       " 41,\n",
       " 96,\n",
       " 46,\n",
       " 69,\n",
       " 42,\n",
       " 66,\n",
       " 46,\n",
       " 96,\n",
       " 64,\n",
       " 68,\n",
       " 34,\n",
       " 68,\n",
       " 53,\n",
       " 80,\n",
       " 36,\n",
       " 90,\n",
       " 16,\n",
       " 73,\n",
       " 42,\n",
       " 76,\n",
       " 55,\n",
       " 86,\n",
       " 43,\n",
       " 89,\n",
       " 32,\n",
       " 92,\n",
       " 47,\n",
       " 91,\n",
       " 21,\n",
       " 91,\n",
       " 28,\n",
       " 81,\n",
       " 57,\n",
       " 98,\n",
       " 55,\n",
       " 68,\n",
       " 28,\n",
       " 100,\n",
       " 16,\n",
       " 95,\n",
       " 34,\n",
       " 89,\n",
       " 40,\n",
       " 95,\n",
       " 17,\n",
       " 82,\n",
       " 43,\n",
       " 86,\n",
       " 39,\n",
       " 84,\n",
       " 61,\n",
       " 70,\n",
       " 44,\n",
       " 72,\n",
       " 45,\n",
       " 72,\n",
       " 27,\n",
       " 66,\n",
       " 16,\n",
       " 90,\n",
       " 58,\n",
       " 66,\n",
       " 24,\n",
       " 86,\n",
       " 33,\n",
       " 76,\n",
       " 63,\n",
       " 79,\n",
       " 35,\n",
       " 85,\n",
       " 43,\n",
       " 66,\n",
       " 61,\n",
       " 79,\n",
       " 43,\n",
       " 88,\n",
       " 44,\n",
       " 67,\n",
       " 32,\n",
       " 89,\n",
       " 48,\n",
       " 93,\n",
       " 54,\n",
       " 91,\n",
       " 52,\n",
       " 83,\n",
       " 30,\n",
       " 97,\n",
       " 16,\n",
       " 68,\n",
       " 64,\n",
       " 79,\n",
       " 52,\n",
       " 91,\n",
       " 47,\n",
       " 83,\n",
       " 19,\n",
       " 100,\n",
       " 15,\n",
       " 90,\n",
       " 13,\n",
       " 100,\n",
       " 31,\n",
       " 88,\n",
       " 45,\n",
       " 83,\n",
       " 58,\n",
       " 88,\n",
       " 20,\n",
       " 94,\n",
       " 13,\n",
       " 90,\n",
       " 19,\n",
       " 91,\n",
       " 52,\n",
       " 84,\n",
       " 62,\n",
       " 91,\n",
       " 42,\n",
       " 88,\n",
       " 19,\n",
       " 77,\n",
       " 57,\n",
       " 90,\n",
       " 52,\n",
       " 71,\n",
       " 29,\n",
       " 100,\n",
       " 55,\n",
       " 87,\n",
       " 45,\n",
       " 76,\n",
       " 54,\n",
       " 66,\n",
       " 50,\n",
       " 99,\n",
       " 16,\n",
       " 98,\n",
       " 58,\n",
       " 79,\n",
       " 32,\n",
       " 71,\n",
       " 21,\n",
       " 88,\n",
       " 23,\n",
       " 100,\n",
       " 42,\n",
       " 97,\n",
       " 31,\n",
       " 93,\n",
       " 42,\n",
       " 92,\n",
       " 42,\n",
       " 75,\n",
       " 23,\n",
       " 68,\n",
       " 60,\n",
       " 79,\n",
       " 60,\n",
       " 81,\n",
       " 51,\n",
       " 85,\n",
       " 21,\n",
       " 92,\n",
       " 40,\n",
       " 94,\n",
       " 28,\n",
       " 80,\n",
       " 45,\n",
       " 73,\n",
       " 64,\n",
       " 98,\n",
       " 57,\n",
       " 74,\n",
       " 34,\n",
       " 87,\n",
       " 34,\n",
       " 79,\n",
       " 16,\n",
       " 72,\n",
       " 14,\n",
       " 90,\n",
       " 25,\n",
       " 68,\n",
       " 54,\n",
       " 99,\n",
       " 59,\n",
       " 83,\n",
       " 14,\n",
       " 67,\n",
       " 53,\n",
       " 95,\n",
       " 42,\n",
       " 74,\n",
       " 40,\n",
       " 67,\n",
       " 56,\n",
       " 71,\n",
       " 38,\n",
       " 69,\n",
       " 64,\n",
       " 67,\n",
       " 25,\n",
       " 89,\n",
       " 41,\n",
       " 88,\n",
       " 51,\n",
       " 88,\n",
       " 61,\n",
       " 88,\n",
       " 47,\n",
       " 94,\n",
       " 13,\n",
       " 97,\n",
       " 57,\n",
       " 85,\n",
       " 38,\n",
       " 98,\n",
       " 49,\n",
       " 76,\n",
       " 49,\n",
       " 95,\n",
       " 57,\n",
       " 66,\n",
       " 58,\n",
       " 78,\n",
       " 49,\n",
       " 85,\n",
       " 30,\n",
       " 65,\n",
       " 57,\n",
       " 96,\n",
       " 59,\n",
       " 88,\n",
       " 62,\n",
       " 66,\n",
       " 15,\n",
       " 83,\n",
       " 32,\n",
       " 81,\n",
       " 60,\n",
       " 72,\n",
       " 44,\n",
       " 89,\n",
       " 64,\n",
       " 88,\n",
       " 62,\n",
       " 71,\n",
       " 33,\n",
       " 78,\n",
       " 52,\n",
       " 76,\n",
       " 18,\n",
       " 65,\n",
       " 41,\n",
       " 77,\n",
       " 43,\n",
       " 90,\n",
       " 21,\n",
       " 99,\n",
       " 28,\n",
       " 86,\n",
       " 33,\n",
       " 73,\n",
       " 21,\n",
       " 95,\n",
       " 46,\n",
       " 77,\n",
       " 56,\n",
       " 84,\n",
       " 62,\n",
       " 80,\n",
       " 63,\n",
       " 89,\n",
       " 50,\n",
       " 68,\n",
       " 50,\n",
       " 73,\n",
       " 26,\n",
       " 73,\n",
       " 38,\n",
       " 89,\n",
       " 15,\n",
       " 81,\n",
       " 62,\n",
       " 87,\n",
       " 63,\n",
       " 81,\n",
       " 44,\n",
       " 98,\n",
       " 20,\n",
       " 92,\n",
       " 56,\n",
       " 93,\n",
       " 25,\n",
       " 69,\n",
       " 38,\n",
       " 72,\n",
       " 13,\n",
       " 95,\n",
       " 50,\n",
       " 68,\n",
       " 59,\n",
       " 79,\n",
       " 51,\n",
       " 68,\n",
       " 61,\n",
       " 72,\n",
       " 57,\n",
       " 95,\n",
       " 26,\n",
       " 98,\n",
       " 19,\n",
       " 86,\n",
       " 45,\n",
       " 71,\n",
       " 23,\n",
       " 76,\n",
       " 35,\n",
       " 94,\n",
       " 61,\n",
       " 86,\n",
       " 29,\n",
       " 77,\n",
       " 50,\n",
       " 95,\n",
       " 18,\n",
       " 68,\n",
       " 15,\n",
       " 75,\n",
       " 28,\n",
       " 84,\n",
       " 14,\n",
       " 73,\n",
       " 51,\n",
       " 91,\n",
       " 36,\n",
       " 97,\n",
       " 14,\n",
       " 93,\n",
       " 63,\n",
       " 69,\n",
       " 15,\n",
       " 65,\n",
       " 17,\n",
       " 71,\n",
       " 41,\n",
       " 68,\n",
       " 49,\n",
       " 68,\n",
       " 39,\n",
       " 97,\n",
       " 36,\n",
       " 95,\n",
       " 61,\n",
       " 77,\n",
       " 36,\n",
       " 99,\n",
       " 30,\n",
       " 91,\n",
       " 43,\n",
       " 66,\n",
       " 24,\n",
       " 96,\n",
       " 14,\n",
       " 95,\n",
       " 54,\n",
       " 72,\n",
       " 24,\n",
       " 77,\n",
       " 36,\n",
       " 65,\n",
       " 20,\n",
       " 91,\n",
       " 27,\n",
       " 94,\n",
       " 51,\n",
       " 86,\n",
       " 32,\n",
       " 89,\n",
       " 63,\n",
       " 77,\n",
       " 15,\n",
       " 77,\n",
       " 57,\n",
       " 86,\n",
       " 13,\n",
       " 71,\n",
       " 30,\n",
       " 90,\n",
       " 58,\n",
       " 79,\n",
       " 43,\n",
       " 74,\n",
       " 13,\n",
       " 82,\n",
       " 16,\n",
       " 92,\n",
       " 43,\n",
       " 71,\n",
       " 57,\n",
       " 72,\n",
       " 60,\n",
       " 69,\n",
       " 62,\n",
       " 97,\n",
       " 41,\n",
       " 88,\n",
       " 19,\n",
       " 100,\n",
       " 51,\n",
       " 91,\n",
       " 19,\n",
       " 85,\n",
       " 26,\n",
       " 80,\n",
       " 60,\n",
       " 68,\n",
       " 63,\n",
       " 87,\n",
       " 22,\n",
       " 73,\n",
       " 36,\n",
       " 95,\n",
       " 60,\n",
       " 84,\n",
       " 39,\n",
       " 93,\n",
       " 20,\n",
       " 69,\n",
       " 45,\n",
       " 90,\n",
       " 39,\n",
       " 66,\n",
       " 58,\n",
       " 96,\n",
       " 26,\n",
       " 90,\n",
       " 16,\n",
       " 86,\n",
       " 56,\n",
       " 92,\n",
       " 53,\n",
       " 100,\n",
       " 62,\n",
       " 86,\n",
       " 53,\n",
       " 84,\n",
       " 41,\n",
       " 84,\n",
       " 45,\n",
       " 92,\n",
       " 55,\n",
       " 98,\n",
       " 43,\n",
       " 71,\n",
       " 14,\n",
       " 84,\n",
       " 53,\n",
       " 76,\n",
       " 30,\n",
       " 74,\n",
       " 49,\n",
       " 77,\n",
       " 19,\n",
       " 97,\n",
       " 49,\n",
       " 85,\n",
       " 39,\n",
       " 84,\n",
       " 14,\n",
       " 68,\n",
       " 29,\n",
       " 75,\n",
       " 25,\n",
       " 79,\n",
       " 34,\n",
       " 81,\n",
       " 43,\n",
       " 89,\n",
       " 40,\n",
       " 70,\n",
       " 29,\n",
       " 95,\n",
       " 44,\n",
       " 77,\n",
       " 56,\n",
       " 88,\n",
       " 63,\n",
       " 86,\n",
       " 17,\n",
       " 98,\n",
       " 47,\n",
       " 88,\n",
       " 35,\n",
       " 88,\n",
       " 45,\n",
       " 76,\n",
       " 56,\n",
       " 81,\n",
       " 53,\n",
       " 66,\n",
       " 57,\n",
       " 78,\n",
       " 19,\n",
       " 84,\n",
       " 33,\n",
       " 83,\n",
       " 64,\n",
       " 74,\n",
       " 43,\n",
       " 94,\n",
       " 17,\n",
       " 100,\n",
       " 62,\n",
       " 100,\n",
       " 62,\n",
       " 73,\n",
       " 26,\n",
       " 75,\n",
       " 30,\n",
       " 90,\n",
       " 58,\n",
       " 87,\n",
       " 23,\n",
       " 94,\n",
       " 15,\n",
       " 93,\n",
       " 59,\n",
       " 95,\n",
       " 63,\n",
       " 82,\n",
       " 26,\n",
       " 95,\n",
       " 56,\n",
       " 92,\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the numerical data into Numpy array which is the accepted input type for machine learning. Also scaling the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = np.array(train_samples)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22988506],\n",
       "       [0.70114943],\n",
       "       [0.4137931 ],\n",
       "       ...,\n",
       "       [0.87356322],\n",
       "       [0.45977011],\n",
       "       [0.73563218]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.6882 - acc: 0.5820 - val_loss: 0.6781 - val_acc: 0.5571\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6679 - acc: 0.6376 - val_loss: 0.6513 - val_acc: 0.6905\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.6432 - acc: 0.6937 - val_loss: 0.6261 - val_acc: 0.7286\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.6208 - acc: 0.7312 - val_loss: 0.6005 - val_acc: 0.7429\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.5979 - acc: 0.7455 - val_loss: 0.5739 - val_acc: 0.7667\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.5742 - acc: 0.7698 - val_loss: 0.5464 - val_acc: 0.7952\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.5502 - acc: 0.7926 - val_loss: 0.5185 - val_acc: 0.8190\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.5263 - acc: 0.8048 - val_loss: 0.4905 - val_acc: 0.8333\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.5031 - acc: 0.8201 - val_loss: 0.4631 - val_acc: 0.8619\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.4807 - acc: 0.8376 - val_loss: 0.4365 - val_acc: 0.8857\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.4594 - acc: 0.8476 - val_loss: 0.4109 - val_acc: 0.8905\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.4393 - acc: 0.8561 - val_loss: 0.3870 - val_acc: 0.9238\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.4209 - acc: 0.8661 - val_loss: 0.3645 - val_acc: 0.9333\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.4041 - acc: 0.8772 - val_loss: 0.3438 - val_acc: 0.9333\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.3891 - acc: 0.8894 - val_loss: 0.3244 - val_acc: 0.9333\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.3756 - acc: 0.8931 - val_loss: 0.3072 - val_acc: 0.9524\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.3636 - acc: 0.8968 - val_loss: 0.2915 - val_acc: 0.9524\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.3529 - acc: 0.9016 - val_loss: 0.2771 - val_acc: 0.9524\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.3435 - acc: 0.9090 - val_loss: 0.2643 - val_acc: 0.9810\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.3351 - acc: 0.9159 - val_loss: 0.2517 - val_acc: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17cf4a51400>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: For below 'fit' method, when we use the 'validation_split' argument, then 'shuffle = True' will not be effective. \n",
    "# For validation, last portion of your actual dataset will be split out.\n",
    "\n",
    "model.fit(scaled_train_samples, train_labels, validation_split=0.1, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Test data\n",
    "\n",
    "We will be creating a test data having a structure similar to training data we created earlier. This test data will have 250 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []\n",
    "\n",
    "for i in range(50):\n",
    "    firstGroup = randint(13, 64)\n",
    "    test_samples.append(firstGroup)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    secondGroup = randint(65, 100)\n",
    "    test_samples.append(secondGroup)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    firstGroup = randint(13, 64)\n",
    "    test_samples.append(firstGroup)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    secondGroup = randint(65, 100)\n",
    "    test_samples.append(secondGroup)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to scaling of training data, now time to scale the test data with scaler fit with training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_samples = scaler.transform((test_samples).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "\n",
    "The test data to be predicted with the model created using training data. Following method 'predict' gives us the probability. \n",
    "* If the value is near 0 then no side-effect, and \n",
    "* if value near 1 then side-effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8734623  0.12653767]\n",
      "[0.18297741 0.8170226 ]\n",
      "[0.8697863  0.13021371]\n",
      "[0.13129705 0.868703  ]\n",
      "[0.8755663  0.12443373]\n",
      "[0.42150483 0.57849514]\n",
      "[0.8164205 0.1835795]\n",
      "[0.06736669 0.93263334]\n",
      "[0.8671415  0.13285848]\n",
      "[0.40245506 0.59754497]\n",
      "[0.87436384 0.12563613]\n",
      "[0.15030067 0.8496993 ]\n",
      "[0.44079104 0.559209  ]\n",
      "[0.18297741 0.8170226 ]\n",
      "[0.8734623  0.12653767]\n",
      "[0.05837237 0.94162756]\n",
      "[0.8752666  0.12473334]\n",
      "[0.07085145 0.92914855]\n",
      "[0.61535317 0.38464683]\n",
      "[0.16062328 0.8393767 ]\n",
      "[0.8664732  0.13352674]\n",
      "[0.40245506 0.59754497]\n",
      "[0.6337917  0.36620834]\n",
      "[0.05301522 0.94698477]\n",
      "[0.47984636 0.5201537 ]\n",
      "[0.05837237 0.94162756]\n",
      "[0.8755663  0.12443373]\n",
      "[0.09938049 0.9006195 ]\n",
      "[0.8734623 0.1265377]\n",
      "[0.16062328 0.8393767 ]\n",
      "[0.65184635 0.3481537 ]\n",
      "[0.07085145 0.92914855]\n",
      "[0.5965773 0.4034227]\n",
      "[0.14053036 0.85946965]\n",
      "[0.669475   0.33052495]\n",
      "[0.14053036 0.85946965]\n",
      "[0.51914966 0.4808504 ]\n",
      "[0.2347438  0.76525617]\n",
      "[0.8734623 0.1265377]\n",
      "[0.0925597 0.9074403]\n",
      "[0.8689565  0.13104352]\n",
      "[0.17151175 0.8284883 ]\n",
      "[0.8386587  0.16134128]\n",
      "[0.29585224 0.70414776]\n",
      "[0.77839553 0.22160445]\n",
      "[0.38369521 0.61630476]\n",
      "[0.70330906 0.29669088]\n",
      "[0.09255972 0.90744025]\n",
      "[0.5965773  0.40342274]\n",
      "[0.34724137 0.65275866]\n",
      "[0.46025777 0.53974223]\n",
      "[0.11437275 0.8856272 ]\n",
      "[0.87388873 0.12611127]\n",
      "[0.38369521 0.61630476]\n",
      "[0.8664732  0.13352674]\n",
      "[0.20767283 0.7923271 ]\n",
      "[0.51914966 0.4808504 ]\n",
      "[0.12258386 0.87741613]\n",
      "[0.669475   0.33052495]\n",
      "[0.42150483 0.57849514]\n",
      "[0.8664732  0.13352674]\n",
      "[0.05301522 0.94698477]\n",
      "[0.46025777 0.53974223]\n",
      "[0.12258386 0.87741613]\n",
      "[0.8279159  0.17208406]\n",
      "[0.15030067 0.8496993 ]\n",
      "[0.8729125  0.12708752]\n",
      "[0.09255972 0.90744025]\n",
      "[0.8456848 0.1543152]\n",
      "[0.13129704 0.868703  ]\n",
      "[0.8729125  0.12708752]\n",
      "[0.10664486 0.89335513]\n",
      "[0.8606693  0.13933073]\n",
      "[0.2347438  0.76525617]\n",
      "[0.7500815  0.24991855]\n",
      "[0.2347438  0.76525617]\n",
      "[0.8755663  0.12443373]\n",
      "[0.3296355 0.6703645]\n",
      "[0.8456848 0.1543152]\n",
      "[0.13129704 0.868703  ]\n",
      "[0.8164205 0.1835795]\n",
      "[0.17151175 0.8284883 ]\n",
      "[0.8678069  0.13219304]\n",
      "[0.18297741 0.8170226 ]\n",
      "[0.8043386  0.19566138]\n",
      "[0.15030067 0.8496993 ]\n",
      "[0.8664732  0.13352674]\n",
      "[0.06736669 0.93263334]\n",
      "[0.7350505 0.2649495]\n",
      "[0.31249487 0.6875052 ]\n",
      "[0.8671415  0.13285848]\n",
      "[0.34724137 0.65275866]\n",
      "[0.8734623  0.12653767]\n",
      "[0.09255972 0.90744025]\n",
      "[0.8755663  0.12443373]\n",
      "[0.29585224 0.70414776]\n",
      "[0.87526    0.12474006]\n",
      "[0.36527532 0.6347247 ]\n",
      "[0.46025777 0.53974223]\n",
      "[0.2491653  0.75083476]\n",
      "[0.5965773 0.4034227]\n",
      "[0.10664486 0.89335513]\n",
      "[0.46025777 0.53974223]\n",
      "[0.06423415 0.9357658 ]\n",
      "[0.7500815  0.24991855]\n",
      "[0.05837237 0.94162756]\n",
      "[0.65184635 0.3481537 ]\n",
      "[0.10664486 0.89335513]\n",
      "[0.8746631  0.12533686]\n",
      "[0.42150483 0.57849514]\n",
      "[0.8704405  0.12955956]\n",
      "[0.15030067 0.8496993 ]\n",
      "[0.8697863  0.13021371]\n",
      "[0.12258386 0.87741613]\n",
      "[0.8689565  0.13104352]\n",
      "[0.20767283 0.7923271 ]\n",
      "[0.5582172  0.44178277]\n",
      "[0.05301522 0.94698477]\n",
      "[0.5191496  0.48085037]\n",
      "[0.40245506 0.59754497]\n",
      "[0.8717404  0.12825964]\n",
      "[0.08016791 0.91983205]\n",
      "[0.8752666  0.12473334]\n",
      "[0.34724137 0.65275866]\n",
      "[0.44079104 0.559209  ]\n",
      "[0.09255972 0.90744025]\n",
      "[0.77839553 0.22160445]\n",
      "[0.34724137 0.65275866]\n",
      "[0.8746631  0.12533686]\n",
      "[0.07487454 0.9251254 ]\n",
      "[0.8704405  0.12955956]\n",
      "[0.42150483 0.57849514]\n",
      "[0.669475   0.33052495]\n",
      "[0.36527532 0.6347247 ]\n",
      "[0.7916645  0.20833552]\n",
      "[0.18297741 0.8170226 ]\n",
      "[0.86912936 0.13087067]\n",
      "[0.05837237 0.94162756]\n",
      "[0.49949718 0.50050277]\n",
      "[0.05301523 0.94698477]\n",
      "[0.8717404  0.12825964]\n",
      "[0.3124949 0.6875051]\n",
      "[0.86846954 0.13153045]\n",
      "[0.38369521 0.61630476]\n",
      "[0.8279159  0.17208406]\n",
      "[0.06736669 0.93263334]\n",
      "[0.8386587  0.16134128]\n",
      "[0.3296355 0.6703645]\n",
      "[0.8743639  0.12563612]\n",
      "[0.27973524 0.72026473]\n",
      "[0.5387429 0.4612572]\n",
      "[0.18297741 0.8170226 ]\n",
      "[0.47984636 0.5201537 ]\n",
      "[0.08016791 0.91983205]\n",
      "[0.8560305  0.14396942]\n",
      "[0.24916527 0.75083476]\n",
      "[0.8734623  0.12653767]\n",
      "[0.05301522 0.94698477]\n",
      "[0.8704405  0.12955958]\n",
      "[0.27973524 0.72026473]\n",
      "[0.6337917  0.36620834]\n",
      "[0.06736669 0.93263334]\n",
      "[0.7194535  0.28054643]\n",
      "[0.11437275 0.8856272 ]\n",
      "[0.87388873 0.12611127]\n",
      "[0.26416695 0.735833  ]\n",
      "[0.57751405 0.42248586]\n",
      "[0.07085145 0.92914855]\n",
      "[0.8386587  0.16134128]\n",
      "[0.06736669 0.93263334]\n",
      "[0.7194535  0.28054643]\n",
      "[0.06123774 0.9387623 ]\n",
      "[0.8755663  0.12443373]\n",
      "[0.19502918 0.8049708 ]\n",
      "[0.8755663  0.12443373]\n",
      "[0.29585224 0.70414776]\n",
      "[0.6337917  0.36620834]\n",
      "[0.09938049 0.9006195 ]\n",
      "[0.440791  0.5592089]\n",
      "[0.07085145 0.92914855]\n",
      "[0.86912936 0.13087067]\n",
      "[0.29585224 0.70414776]\n",
      "[0.87388873 0.12611127]\n",
      "[0.05301522 0.94698477]\n",
      "[0.70330906 0.29669088]\n",
      "[0.08016791 0.91983205]\n",
      "[0.8456848  0.15431522]\n",
      "[0.19502918 0.8049708 ]\n",
      "[0.68664026 0.3133597 ]\n",
      "[0.10664488 0.89335513]\n",
      "[0.44079104 0.559209  ]\n",
      "[0.16062328 0.8393767 ]\n",
      "[0.87388873 0.12611127]\n",
      "[0.06423415 0.9357658 ]\n",
      "[0.8704405  0.12955956]\n",
      "[0.19502918 0.8049708 ]\n",
      "[0.87300944 0.12699054]\n",
      "[0.07487454 0.9251254 ]\n",
      "[0.8386587  0.16134128]\n",
      "[0.08616225 0.91383773]\n",
      "[0.5582172  0.44178277]\n",
      "[0.2347438  0.76525617]\n",
      "[0.8043386  0.19566138]\n",
      "[0.08616223 0.9138378 ]\n",
      "[0.86846954 0.13153045]\n",
      "[0.34724137 0.65275866]\n",
      "[0.8456848  0.15431522]\n",
      "[0.20767283 0.7923271 ]\n",
      "[0.8704405  0.12955958]\n",
      "[0.05563316 0.9443669 ]\n",
      "[0.57751405 0.42248586]\n",
      "[0.09938049 0.9006195 ]\n",
      "[0.8710918 0.1289082]\n",
      "[0.24916527 0.75083476]\n",
      "[0.87388873 0.12611127]\n",
      "[0.38369521 0.61630476]\n",
      "[0.47984636 0.5201537 ]\n",
      "[0.3124949 0.6875051]\n",
      "[0.5775141 0.4224859]\n",
      "[0.26416698 0.735833  ]\n",
      "[0.87300944 0.12699054]\n",
      "[0.3296355 0.6703645]\n",
      "[0.70330906 0.29669088]\n",
      "[0.12258386 0.87741613]\n",
      "[0.7500815  0.24991855]\n",
      "[0.19502918 0.8049708 ]\n",
      "[0.57751405 0.42248586]\n",
      "[0.05301522 0.94698477]\n",
      "[0.8734623 0.1265377]\n",
      "[0.40245506 0.59754497]\n",
      "[0.8748126  0.12518738]\n",
      "[0.29585224 0.70414776]\n",
      "[0.669475   0.33052495]\n",
      "[0.10664486 0.89335513]\n",
      "[0.8164205 0.1835795]\n",
      "[0.15030067 0.8496993 ]\n",
      "[0.5965773 0.4034227]\n",
      "[0.24916527 0.75083476]\n",
      "[0.87526    0.12474006]\n",
      "[0.05837237 0.94162756]\n",
      "[0.7350505 0.2649495]\n",
      "[0.05301522 0.94698477]\n",
      "[0.8729125  0.12708752]\n",
      "[0.06423415 0.9357658 ]\n",
      "[0.8456848  0.15431522]\n",
      "[0.38369521 0.61630476]\n",
      "[0.8739138  0.12608622]\n",
      "[0.05301522 0.94698477]\n",
      "[0.8729125 0.1270875]\n",
      "[0.15030068 0.8496993 ]\n",
      "[0.8678069  0.13219304]\n",
      "[0.14053036 0.85946965]\n",
      "[0.7645329  0.23546712]\n",
      "[0.38369521 0.61630476]\n",
      "[0.8704405  0.12955956]\n",
      "[0.07487454 0.9251254 ]\n",
      "[0.8043386  0.19566138]\n",
      "[0.08016791 0.91983205]\n",
      "[0.8729125 0.1270875]\n",
      "[0.10664488 0.89335513]\n",
      "[0.8746631  0.12533684]\n",
      "[0.07487454 0.9251254 ]\n",
      "[0.8748126  0.12518738]\n",
      "[0.06123774 0.9387623 ]\n",
      "[0.8606693  0.13933073]\n",
      "[0.15030067 0.8496993 ]\n",
      "[0.87526    0.12474006]\n",
      "[0.19502918 0.8049708 ]\n",
      "[0.7500815  0.24991855]\n",
      "[0.22091144 0.77908856]\n",
      "[0.8752666  0.12473334]\n",
      "[0.3124949 0.6875051]\n",
      "[0.8678069  0.13219304]\n",
      "[0.06123774 0.9387623 ]\n",
      "[0.8739138  0.12608622]\n",
      "[0.17151175 0.8284883 ]\n",
      "[0.8456848  0.15431522]\n",
      "[0.07487454 0.9251254 ]\n",
      "[0.7194535  0.28054643]\n",
      "[0.2491653  0.75083476]\n",
      "[0.5387429 0.4612572]\n",
      "[0.24916527 0.75083476]\n",
      "[0.8164205 0.1835795]\n",
      "[0.06423415 0.9357658 ]\n",
      "[0.44079104 0.559209  ]\n",
      "[0.09255972 0.90744025]\n",
      "[0.46025777 0.53974223]\n",
      "[0.27973527 0.72026473]\n",
      "[0.8755663  0.12443371]\n",
      "[0.27973524 0.72026473]\n",
      "[0.8560305  0.14396942]\n",
      "[0.09255972 0.90744025]\n",
      "[0.7645329  0.23546712]\n",
      "[0.07487454 0.9251254 ]\n",
      "[0.8752666  0.12473334]\n",
      "[0.2347438  0.76525617]\n",
      "[0.7194535  0.28054643]\n",
      "[0.12258386 0.87741613]\n",
      "[0.8689565  0.13104351]\n",
      "[0.06423416 0.9357658 ]\n",
      "[0.87388873 0.12611127]\n",
      "[0.26416695 0.735833  ]\n",
      "[0.8456848  0.15431522]\n",
      "[0.17151175 0.8284883 ]\n",
      "[0.8678069  0.13219304]\n",
      "[0.13129705 0.868703  ]\n",
      "[0.87238616 0.12761386]\n",
      "[0.19502918 0.8049708 ]\n",
      "[0.5191496  0.48085037]\n",
      "[0.22091144 0.77908856]\n",
      "[0.8164205 0.1835795]\n",
      "[0.36527532 0.6347247 ]\n",
      "[0.87300944 0.12699054]\n",
      "[0.06423415 0.9357658 ]\n",
      "[0.49949718 0.50050277]\n",
      "[0.36527532 0.6347247 ]\n",
      "[0.5582172  0.44178277]\n",
      "[0.07487454 0.9251254 ]\n",
      "[0.8664732  0.13352674]\n",
      "[0.07085145 0.92914855]\n",
      "[0.7350505 0.2649495]\n",
      "[0.3296355 0.6703645]\n",
      "[0.8671415  0.13285848]\n",
      "[0.19502918 0.8049708 ]\n",
      "[0.87238616 0.12761386]\n",
      "[0.42150483 0.57849514]\n",
      "[0.8456848  0.15431522]\n",
      "[0.12258386 0.87741613]\n",
      "[0.7350505 0.2649495]\n",
      "[0.18297744 0.8170226 ]\n",
      "[0.8606693  0.13933073]\n",
      "[0.09255972 0.90744025]\n",
      "[0.65184635 0.3481537 ]\n",
      "[0.36527532 0.6347247 ]\n",
      "[0.47984636 0.5201537 ]\n",
      "[0.34724137 0.65275866]\n",
      "[0.61535317 0.38464683]\n",
      "[0.42150483 0.57849514]\n",
      "[0.7916645  0.20833555]\n",
      "[0.09938046 0.9006195 ]\n",
      "[0.7350505 0.2649495]\n",
      "[0.26416695 0.735833  ]\n",
      "[0.8755663  0.12443373]\n",
      "[0.2347438  0.76525617]\n",
      "[0.8697863  0.13021371]\n",
      "[0.05837237 0.94162756]\n",
      "[0.8734623  0.12653767]\n",
      "[0.17151175 0.8284883 ]\n",
      "[0.7500815  0.24991855]\n",
      "[0.40245506 0.59754497]\n",
      "[0.8164205 0.1835795]\n",
      "[0.11437275 0.8856272 ]\n",
      "[0.8734623  0.12653767]\n",
      "[0.38369521 0.61630476]\n",
      "[0.8697863  0.13021371]\n",
      "[0.09255972 0.90744025]\n",
      "[0.8678069  0.13219304]\n",
      "[0.06123774 0.9387623 ]\n",
      "[0.61535317 0.38464683]\n",
      "[0.11437275 0.8856272 ]\n",
      "[0.8689565  0.13104352]\n",
      "[0.12258386 0.87741613]\n",
      "[0.5582172  0.44178277]\n",
      "[0.13129705 0.868703  ]\n",
      "[0.8739138  0.12608622]\n",
      "[0.08016791 0.91983205]\n",
      "[0.86846954 0.13153045]\n",
      "[0.16062328 0.8393767 ]\n",
      "[0.8743639  0.12563612]\n",
      "[0.34724137 0.65275866]\n",
      "[0.68664026 0.3133597 ]\n",
      "[0.3124949 0.6875051]\n",
      "[0.49949718 0.50050277]\n",
      "[0.06736669 0.93263334]\n",
      "[0.87300944 0.12699054]\n",
      "[0.42150483 0.57849514]\n",
      "[0.86488146 0.13511853]\n",
      "[0.2347438  0.76525617]\n",
      "[0.8560305 0.1439694]\n",
      "[0.13129704 0.868703  ]\n",
      "[0.87388873 0.12611127]\n",
      "[0.07487454 0.9251254 ]\n",
      "[0.77839553 0.22160445]\n",
      "[0.34724137 0.65275866]\n",
      "[0.8164205 0.1835795]\n",
      "[0.38369521 0.61630476]\n",
      "[0.87238616 0.12761386]\n",
      "[0.29585224 0.70414776]\n",
      "[0.8043386  0.19566138]\n",
      "[0.3836952 0.6163048]\n",
      "[0.70330906 0.29669088]\n",
      "[0.06736669 0.93263334]\n",
      "[0.86912936 0.13087067]\n",
      "[0.05301522 0.94698477]\n",
      "[0.44079104 0.559209  ]\n",
      "[0.13129705 0.868703  ]\n",
      "[0.8748126  0.12518738]\n",
      "[0.08016791 0.91983205]\n",
      "[0.8164205 0.1835795]\n",
      "[0.0925597 0.9074403]\n",
      "[0.5387429 0.4612572]\n",
      "[0.05563316 0.9443669 ]\n",
      "[0.8456848  0.15431522]\n",
      "[0.07487454 0.9251254 ]\n",
      "[0.8717404  0.12825964]\n",
      "[0.15030067 0.8496993 ]\n",
      "[0.8704405  0.12955956]\n",
      "[0.19502918 0.8049708 ]\n",
      "[0.61535317 0.38464683]\n",
      "[0.05837237 0.94162756]\n",
      "[0.86488146 0.13511853]\n",
      "[0.20767283 0.7923271 ]\n",
      "[0.51914966 0.4808504 ]\n",
      "[0.29585224 0.70414776]\n",
      "[0.8664732  0.13352674]\n",
      "[0.18297741 0.8170226 ]\n",
      "[0.44079104 0.559209  ]\n",
      "[0.05301522 0.94698477]\n",
      "[0.86488146 0.13511853]\n",
      "[0.06736669 0.93263334]\n",
      "[0.46025777 0.53974223]\n",
      "[0.3296355 0.6703645]\n",
      "[0.8560305  0.14396942]\n",
      "[0.06423415 0.9357658 ]\n",
      "[0.77839553 0.22160445]\n",
      "[0.24916527 0.75083476]\n",
      "[0.8729125  0.12708752]\n",
      "[0.29585224 0.70414776]\n",
      "[0.86912924 0.13087067]\n",
      "[0.13129704 0.868703  ]\n",
      "[0.8755663  0.12443373]\n",
      "[0.09255972 0.90744025]\n",
      "[0.8279159  0.17208406]\n",
      "[0.36527532 0.6347247 ]\n",
      "[0.8704405  0.12955956]\n",
      "[0.19502918 0.8049708 ]\n",
      "[0.8748126  0.12518738]\n",
      "[0.07487454 0.9251254 ]\n",
      "[0.8734623 0.1265377]\n",
      "[0.06123774 0.9387623 ]\n",
      "[0.7350505 0.2649495]\n",
      "[0.06123774 0.9387623 ]\n",
      "[0.6337917  0.36620834]\n",
      "[0.13129705 0.868703  ]\n",
      "[0.8734623  0.12653767]\n",
      "[0.2347438  0.76525617]\n",
      "[0.6337917  0.36620834]\n",
      "[0.07085145 0.92914855]\n",
      "[0.85117984 0.14882013]\n",
      "[0.06736669 0.93263334]\n",
      "[0.5965773 0.4034227]\n",
      "[0.19502918 0.8049708 ]\n",
      "[0.8746631  0.12533684]\n",
      "[0.09938049 0.9006195 ]\n",
      "[0.7645329  0.23546712]\n",
      "[0.24916527 0.75083476]\n",
      "[0.8606693  0.13933073]\n",
      "[0.08016791 0.91983205]\n",
      "[0.86488146 0.13511853]\n",
      "[0.08016791 0.91983205]\n",
      "[0.8729125  0.12708752]\n",
      "[0.09255972 0.90744025]\n",
      "[0.8752666  0.12473334]\n",
      "[0.3296355 0.6703645]\n",
      "[0.8664732  0.13352674]\n",
      "[0.3296355 0.6703645]\n",
      "[0.47984636 0.5201537 ]\n",
      "[0.16062328 0.8393767 ]\n",
      "[0.8164205 0.1835795]\n",
      "[0.09938046 0.9006195 ]\n",
      "[0.8279159  0.17208406]\n",
      "[0.14053036 0.85946965]\n",
      "[0.51914966 0.4808504 ]\n",
      "[0.06423415 0.9357658 ]\n",
      "[0.8689565  0.13104352]\n",
      "[0.06123774 0.9387623 ]\n",
      "[0.8456848  0.15431522]\n",
      "[0.07085145 0.92914855]\n",
      "[0.68664026 0.3133597 ]\n",
      "[0.13129704 0.868703  ]\n",
      "[0.8746631  0.12533684]\n",
      "[0.40245506 0.59754497]\n",
      "[0.51914966 0.4808504 ]\n",
      "[0.36527532 0.6347247 ]\n",
      "[0.7500815  0.24991855]\n",
      "[0.07487454 0.9251254 ]\n",
      "[0.49949718 0.50050277]\n",
      "[0.05837237 0.94162756]\n",
      "[0.87388873 0.12611127]\n",
      "[0.14053035 0.85946965]\n",
      "[0.8456848  0.15431522]\n",
      "[0.17151175 0.8284883 ]\n",
      "[0.8755663  0.12443373]\n",
      "[0.05837237 0.94162756]\n",
      "[0.8560305  0.14396942]\n",
      "[0.3296355 0.6703645]\n",
      "[0.8689565  0.13104352]\n",
      "[0.42150483 0.57849514]\n",
      "[0.669475   0.33052495]\n",
      "[0.05301523 0.94698477]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Time to see how well our model has performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following function plots the Confusion Matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=False):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Normalized Confusion Matrix')\n",
    "    else:\n",
    "        print('Confusion Matrix, without Normalization')\n",
    "        \n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix, without Normalization\n",
      "[[183  67]\n",
      " [ 45 205]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the plotting function\n",
    "\n",
    "cm_plot_labels = ['No_Side_Effects', 'Had_Side_Effects']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "To save the model on the local machine.\n",
    "\n",
    "###### Type 1: To save the complete model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('E:\\\\\\Machine_Learning\\\\Models\\\\medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('E:\\\\\\Machine_Learning\\\\Models\\\\medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.01634306, -0.5630061 ,  0.73466563,  0.2115582 ,  0.25421852,\n",
       "         -0.5817262 , -0.38309842,  0.444582  , -0.3470469 , -0.09929711,\n",
       "         -0.25366804, -0.0107376 ,  0.2437472 , -0.07597083,  0.49209857,\n",
       "          0.4206006 ]], dtype=float32),\n",
       " array([ 0.        ,  0.        , -0.10875339,  0.17644982, -0.07851986,\n",
       "         0.        ,  0.        , -0.11417267,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.2246139 ,  0.        , -0.11568926,\n",
       "        -0.12246583], dtype=float32),\n",
       " array([[-5.11497259e-04,  1.27931863e-01,  3.19787115e-01,\n",
       "         -2.11004913e-02,  2.88741559e-01, -4.02800739e-02,\n",
       "          9.09093916e-02, -2.97500610e-01,  2.30067402e-01,\n",
       "         -1.61369443e-02,  6.61724806e-02,  1.31860465e-01,\n",
       "          8.30626786e-02, -3.60675156e-02,  9.25183296e-03,\n",
       "          5.77282906e-02, -2.01852545e-01, -5.14090359e-02,\n",
       "         -9.43182409e-02, -1.13091037e-01,  3.49128217e-01,\n",
       "         -2.70555198e-01, -2.89139271e-01, -1.65609211e-01,\n",
       "         -1.84925199e-02,  1.44075751e-02,  3.22037667e-01,\n",
       "          4.62994874e-02, -2.85171062e-01,  2.45852619e-01,\n",
       "         -5.04313111e-02, -2.56611764e-01],\n",
       "        [ 3.16289574e-01, -3.46699536e-01, -2.46106058e-01,\n",
       "          2.34564573e-01, -1.30302012e-02,  5.34648895e-02,\n",
       "         -2.14616552e-01,  9.99585092e-02,  2.26033181e-01,\n",
       "         -3.21387768e-01, -3.15356612e-01,  3.43865663e-01,\n",
       "          9.82997715e-02,  1.46370828e-02,  2.71988004e-01,\n",
       "          3.06656390e-01,  1.61941618e-01, -2.46067643e-02,\n",
       "         -1.27927065e-01,  1.70595676e-01, -1.14291310e-02,\n",
       "         -2.34527737e-01, -2.86428034e-01,  3.23547035e-01,\n",
       "         -3.92502546e-02,  1.90244526e-01,  1.45585924e-01,\n",
       "         -3.04845214e-01, -2.21854940e-01, -2.50021428e-01,\n",
       "         -2.16741174e-01,  3.33415896e-01],\n",
       "        [-2.52486587e-01, -2.99733490e-01,  4.05895114e-02,\n",
       "          1.07931346e-01, -2.36293048e-01, -4.10907090e-01,\n",
       "          3.72902423e-01, -2.04055801e-01,  3.95621628e-01,\n",
       "          2.68088549e-01,  4.62800086e-01, -2.06638891e-02,\n",
       "          1.19946085e-01,  9.25470367e-02, -3.46516788e-01,\n",
       "         -2.24529237e-01,  4.67711776e-01,  4.63986367e-01,\n",
       "          1.32565508e-02,  4.37140465e-02, -1.52988836e-01,\n",
       "          2.02262595e-01, -2.64705569e-02, -1.39452964e-01,\n",
       "          4.48021322e-01,  5.19749939e-01,  4.75976497e-01,\n",
       "          2.07197338e-01, -6.96712732e-03,  6.85037374e-02,\n",
       "          2.40279496e-01, -5.40472269e-02],\n",
       "        [-7.34552741e-03,  7.47078210e-02, -9.74196494e-02,\n",
       "          1.12318099e-02,  1.34127066e-01,  7.06951693e-02,\n",
       "          1.02478489e-01,  2.49223113e-01, -3.17002870e-02,\n",
       "          2.11598352e-01,  3.32049727e-01,  2.03382313e-01,\n",
       "          4.76100743e-02,  2.99332947e-01, -1.79431275e-01,\n",
       "          1.22945219e-01, -1.53105766e-01,  2.62440234e-01,\n",
       "         -4.39463742e-03,  3.53167802e-01,  5.56277437e-03,\n",
       "          3.04833740e-01,  2.18289241e-01, -2.43595969e-02,\n",
       "          3.01524043e-01,  2.72436172e-01, -9.83260274e-02,\n",
       "         -1.93811320e-02, -3.52314681e-01,  2.46309191e-01,\n",
       "         -1.12189762e-01,  2.74448581e-02],\n",
       "        [-3.51776898e-01, -5.26339971e-02, -2.07108855e-01,\n",
       "         -2.96921164e-01, -1.80945039e-01,  2.50432808e-02,\n",
       "          4.00922865e-01, -9.67454240e-02,  5.20864367e-01,\n",
       "          2.29287863e-01,  2.15030462e-01, -3.16012084e-01,\n",
       "         -4.57703710e-01, -4.72147584e-01,  9.20951366e-03,\n",
       "         -2.73583531e-02,  4.05351311e-01,  1.76074311e-01,\n",
       "         -1.80297405e-01, -3.35531056e-01,  1.51797861e-01,\n",
       "          3.45731437e-01, -2.29865700e-01,  2.48327360e-01,\n",
       "         -3.31325606e-02,  5.51988967e-02,  4.58623499e-01,\n",
       "          2.06248492e-01, -2.69509554e-01, -1.92560375e-01,\n",
       "          5.82839429e-01, -1.86253965e-01],\n",
       "        [ 1.24503642e-01, -2.12585166e-01, -9.85013843e-02,\n",
       "         -1.38058826e-01,  3.33898515e-01,  1.43264800e-01,\n",
       "          7.17121959e-02,  1.84719831e-01,  3.41608137e-01,\n",
       "          2.59040743e-01, -2.62400508e-02, -2.45624661e-01,\n",
       "         -2.78492033e-01,  7.99818337e-02,  2.74172157e-01,\n",
       "          2.53018469e-01,  1.92846209e-01, -2.70890176e-01,\n",
       "         -1.74442425e-01, -1.63189217e-01,  2.05009609e-01,\n",
       "          1.43383235e-01,  5.99842370e-02, -5.04114330e-02,\n",
       "          3.13453525e-01, -3.22703660e-01, -1.99016318e-01,\n",
       "          2.04250902e-01,  1.55375630e-01, -2.10974813e-01,\n",
       "         -2.29237214e-01,  2.95280486e-01],\n",
       "        [-3.53344589e-01,  1.20776683e-01,  7.95806646e-02,\n",
       "         -3.49754870e-01, -5.65653741e-02, -1.65584087e-02,\n",
       "         -1.36670336e-01,  2.74297446e-01,  2.49248594e-01,\n",
       "         -5.24273813e-02,  2.10928053e-01,  2.45831460e-01,\n",
       "          2.56358087e-02,  1.94426864e-01, -7.07321167e-02,\n",
       "         -3.04414541e-01, -1.35096908e-03,  6.96671009e-03,\n",
       "         -3.09640169e-01,  2.15161532e-01, -2.87388742e-01,\n",
       "          1.52216822e-01, -1.98885798e-02,  1.16272271e-01,\n",
       "         -2.83046782e-01,  2.10948855e-01,  2.74394423e-01,\n",
       "          2.33715385e-01,  1.28984600e-01,  2.24062413e-01,\n",
       "         -5.62427640e-02, -1.71192154e-01],\n",
       "        [-3.38692158e-01, -5.41143678e-02,  9.51024294e-02,\n",
       "          2.11508870e-02, -4.99242917e-02, -9.56063643e-02,\n",
       "          4.28766489e-01, -2.69740582e-01, -1.15985990e-01,\n",
       "         -1.01431482e-01, -9.56494734e-02, -4.27799910e-01,\n",
       "         -3.27083886e-01, -1.98581889e-01, -8.04955959e-02,\n",
       "         -5.22916913e-02,  3.93207848e-01, -7.84205720e-02,\n",
       "          1.63259789e-01,  6.42796755e-02, -1.48421898e-01,\n",
       "          2.62318611e-01,  1.19342074e-01, -2.29492784e-01,\n",
       "          5.63743055e-01, -1.05676048e-01,  1.65990353e-01,\n",
       "          4.87454206e-01, -9.33793783e-02, -4.70363796e-01,\n",
       "          2.62572885e-01, -3.35018903e-01],\n",
       "        [ 2.84972936e-01, -1.54353395e-01, -1.04767367e-01,\n",
       "         -1.01198852e-02, -2.32248768e-01, -1.35001153e-01,\n",
       "         -3.47352743e-01,  2.08577067e-01, -2.29679331e-01,\n",
       "          9.79050994e-02,  1.06138498e-01,  8.47755969e-02,\n",
       "         -7.00442791e-02, -2.02602446e-02,  2.27999419e-01,\n",
       "          2.25668460e-01, -2.43784696e-01, -2.73501098e-01,\n",
       "         -1.61883846e-01,  1.80709511e-01,  2.40083426e-01,\n",
       "          1.67855829e-01,  2.37480015e-01,  1.78542465e-01,\n",
       "         -3.43554378e-01,  1.59628719e-01,  2.03977674e-01,\n",
       "          3.44552845e-01, -2.77619779e-01,  7.02115893e-02,\n",
       "         -2.08670139e-01, -6.97839558e-02],\n",
       "        [-4.43047583e-02, -2.33087495e-01, -1.64339319e-01,\n",
       "          4.24725711e-02, -6.88132644e-03, -1.23994172e-01,\n",
       "          2.79156774e-01, -1.98847398e-01,  1.73296601e-01,\n",
       "         -1.60712510e-01,  2.60832578e-01,  3.09575111e-01,\n",
       "         -3.49161923e-01, -2.10891947e-01,  1.68581635e-01,\n",
       "         -1.38190329e-01,  1.91168785e-02, -3.26107353e-01,\n",
       "         -2.69825131e-01,  7.48335123e-02,  8.41326118e-02,\n",
       "          3.03839177e-01, -3.44306707e-01,  9.11900103e-02,\n",
       "         -1.18931741e-01, -2.69124568e-01, -7.66261816e-02,\n",
       "         -2.02165529e-01,  8.17698240e-03,  3.64701748e-02,\n",
       "          2.72725016e-01,  1.79957122e-01],\n",
       "        [ 2.59967476e-01,  2.52232760e-01, -3.08346242e-01,\n",
       "          1.17264748e-01, -1.80730313e-01,  1.21091932e-01,\n",
       "          6.86764419e-02,  4.50583398e-02,  1.56966835e-01,\n",
       "          2.72700697e-01,  5.87956905e-02,  1.81571752e-01,\n",
       "         -3.26292962e-01, -1.48574039e-01, -9.73734260e-03,\n",
       "         -2.55042881e-01,  3.81802320e-02, -3.06811512e-01,\n",
       "          1.10229760e-01, -3.09318006e-01,  2.90708572e-01,\n",
       "          6.01072311e-02,  2.58794457e-01,  1.17677361e-01,\n",
       "         -8.07930529e-02, -7.82456994e-02,  1.08923882e-01,\n",
       "         -2.56078243e-02, -1.96552664e-01, -2.44330496e-01,\n",
       "          1.36232972e-02,  1.60603374e-01],\n",
       "        [ 1.29228234e-02, -3.39894772e-01, -2.56513208e-01,\n",
       "         -5.02423346e-02, -3.01655263e-01,  8.70835781e-02,\n",
       "         -2.62162000e-01, -4.47658598e-02, -6.56996071e-02,\n",
       "          3.16387445e-01, -1.09282315e-01,  2.95306295e-01,\n",
       "         -2.15509892e-01,  7.87429512e-02,  8.93724859e-02,\n",
       "         -3.42130661e-05, -2.35774606e-01,  3.34066153e-02,\n",
       "         -1.65871784e-01,  2.24524736e-03, -1.37310222e-01,\n",
       "         -3.32542688e-01, -2.40296379e-01, -1.16168678e-01,\n",
       "          1.82253748e-01, -8.11500549e-02,  2.57529825e-01,\n",
       "          6.54662848e-02,  2.06921309e-01,  1.94271594e-01,\n",
       "          2.74691075e-01,  1.20607316e-02],\n",
       "        [-2.45931149e-02,  2.16168925e-01, -3.07068527e-01,\n",
       "         -2.81970859e-01, -6.94677755e-02,  2.26846069e-01,\n",
       "          3.51592720e-01, -1.26305848e-01,  2.22682655e-01,\n",
       "          2.07795203e-01, -2.39836667e-02,  2.28815615e-01,\n",
       "          3.00478429e-01,  2.31761828e-01,  6.84845746e-02,\n",
       "         -1.21573344e-01,  3.62118423e-01,  1.32558122e-01,\n",
       "          9.55697671e-02, -2.98582256e-01, -3.49102542e-02,\n",
       "         -2.78885700e-02, -2.42658123e-01, -5.37359007e-02,\n",
       "          3.78354579e-01,  2.36780405e-01, -1.33014023e-01,\n",
       "         -7.58196414e-02, -3.33837569e-02,  2.50591695e-01,\n",
       "          1.00614980e-01,  3.46145153e-01],\n",
       "        [-1.82539821e-02, -3.35703939e-01, -3.10418457e-01,\n",
       "         -4.13839817e-02,  1.20055974e-01, -4.21365499e-02,\n",
       "         -5.12692034e-02, -1.35175884e-02,  2.01436669e-01,\n",
       "         -2.16369271e-01,  2.05361277e-01, -9.04649198e-02,\n",
       "         -1.58982545e-01,  1.25846535e-01,  2.37918764e-01,\n",
       "          2.52440721e-01,  4.41342294e-02,  2.30922729e-01,\n",
       "         -4.05482948e-02,  4.44361567e-03, -2.28079095e-01,\n",
       "          4.44442630e-02,  1.28979385e-02,  1.65564090e-01,\n",
       "         -2.69597799e-01,  2.82735974e-01,  2.70937830e-01,\n",
       "         -2.94202358e-01, -2.43471131e-01, -3.10527980e-02,\n",
       "          2.24509150e-01, -3.40666652e-01],\n",
       "        [-3.66137326e-02, -1.92948103e-01, -1.67714283e-01,\n",
       "         -1.63602009e-01,  9.39963311e-02, -1.27887949e-01,\n",
       "          5.57450831e-01,  5.20935059e-02,  2.69783914e-01,\n",
       "          7.70993009e-02,  6.86462671e-02, -3.74299049e-01,\n",
       "         -4.73327696e-01, -4.49012071e-01,  2.37580627e-01,\n",
       "         -1.84195340e-02,  3.89761835e-01,  4.21500087e-01,\n",
       "         -2.81642616e-01, -3.16736609e-01,  8.83966088e-02,\n",
       "         -8.48907009e-02, -1.70304805e-01,  3.63521576e-02,\n",
       "          3.26491058e-01,  1.71340510e-01,  3.02392632e-01,\n",
       "          4.48549241e-01, -3.38315457e-01, -5.01481965e-02,\n",
       "          2.25645438e-01, -4.65330273e-01],\n",
       "        [-2.41161555e-01, -2.03866303e-01, -1.74641699e-01,\n",
       "         -4.13805246e-03, -2.98505962e-01,  5.82900904e-02,\n",
       "          3.71830910e-01,  2.56309122e-01,  4.75571215e-01,\n",
       "          3.72858316e-01,  1.26529723e-01, -2.33325034e-01,\n",
       "         -4.45012927e-01,  5.27213216e-02, -1.56015828e-01,\n",
       "          1.86533779e-01,  2.42020756e-01,  4.24307674e-01,\n",
       "         -2.93924361e-01,  1.63117081e-01, -3.11301082e-01,\n",
       "          3.21330070e-01, -5.39622664e-01,  2.49597579e-01,\n",
       "          4.69966143e-01, -8.41264147e-03,  1.29854545e-01,\n",
       "         -1.10940382e-01,  2.21409887e-01, -3.20531368e-01,\n",
       "          2.16449395e-01, -2.38784969e-01]], dtype=float32),\n",
       " array([ 0.        ,  0.19129185,  0.        ,  0.        ,  0.19820844,\n",
       "         0.16509704, -0.12377162, -0.01908098, -0.0874985 , -0.10525509,\n",
       "        -0.09677671,  0.200298  ,  0.22094753,  0.16016808,  0.        ,\n",
       "         0.        , -0.09836863, -0.10489105, -0.02663722,  0.        ,\n",
       "        -0.00056281, -0.07924068,  0.23163931, -0.00150063, -0.15106264,\n",
       "        -0.12997615, -0.03295687, -0.03529377,  0.        ,  0.15214558,\n",
       "        -0.05040816,  0.21656069], dtype=float32),\n",
       " array([[-0.3028408 ,  0.10765031],\n",
       "        [ 0.14157476, -0.61053276],\n",
       "        [ 0.08815917, -0.34736907],\n",
       "        [ 0.16483095, -0.34194887],\n",
       "        [ 0.7226877 , -0.12786639],\n",
       "        [ 0.6113498 , -0.4663111 ],\n",
       "        [-0.16180462,  0.26315126],\n",
       "        [-0.13043068,  0.1150819 ],\n",
       "        [-0.3807517 ,  0.29600918],\n",
       "        [-0.53430325,  0.37233034],\n",
       "        [-0.25722095,  0.26978958],\n",
       "        [ 0.7676398 , -0.59869784],\n",
       "        [ 0.46732375, -0.27143857],\n",
       "        [ 0.27070636, -0.05644391],\n",
       "        [ 0.03028211, -0.22487189],\n",
       "        [ 0.02726671, -0.29540834],\n",
       "        [-0.37435868,  0.14072926],\n",
       "        [-0.36700276,  0.32920778],\n",
       "        [-0.34736252,  0.00295176],\n",
       "        [ 0.08526525, -0.07036379],\n",
       "        [ 0.02533339,  0.11319116],\n",
       "        [-0.40156585, -0.17370741],\n",
       "        [ 0.45768076, -0.28036532],\n",
       "        [-0.20226286,  0.05095496],\n",
       "        [ 0.10013375,  0.497827  ],\n",
       "        [ 0.0024695 ,  0.3872898 ],\n",
       "        [-0.21671388,  0.4103309 ],\n",
       "        [-0.6118391 ,  0.38492522],\n",
       "        [-0.25990278, -0.35260373],\n",
       "        [ 0.28547537, -0.40263763],\n",
       "        [-0.30777597,  0.37498036],\n",
       "        [ 0.53188425, -0.5415132 ]], dtype=float32),\n",
       " array([ 0.13897736, -0.1389774 ], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.Adam at 0x1f70603b630>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Type 2: To store the model architecture alone and not its weights and optimizer, use method 'to_json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Type 3: To save alone the weights and not the architecture use method 'save_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('E:\\\\\\Machine_Learning\\\\Models\\\\medical_trial_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('E:\\\\\\Machine_Learning\\\\Models\\\\medical_trial_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.01634306, -0.5630061 ,  0.73466563,  0.2115582 ,  0.25421852,\n",
       "         -0.5817262 , -0.38309842,  0.444582  , -0.3470469 , -0.09929711,\n",
       "         -0.25366804, -0.0107376 ,  0.2437472 , -0.07597083,  0.49209857,\n",
       "          0.4206006 ]], dtype=float32),\n",
       " array([ 0.        ,  0.        , -0.10875339,  0.17644982, -0.07851986,\n",
       "         0.        ,  0.        , -0.11417267,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.2246139 ,  0.        , -0.11568926,\n",
       "        -0.12246583], dtype=float32),\n",
       " array([[-5.11497259e-04,  1.27931863e-01,  3.19787115e-01,\n",
       "         -2.11004913e-02,  2.88741559e-01, -4.02800739e-02,\n",
       "          9.09093916e-02, -2.97500610e-01,  2.30067402e-01,\n",
       "         -1.61369443e-02,  6.61724806e-02,  1.31860465e-01,\n",
       "          8.30626786e-02, -3.60675156e-02,  9.25183296e-03,\n",
       "          5.77282906e-02, -2.01852545e-01, -5.14090359e-02,\n",
       "         -9.43182409e-02, -1.13091037e-01,  3.49128217e-01,\n",
       "         -2.70555198e-01, -2.89139271e-01, -1.65609211e-01,\n",
       "         -1.84925199e-02,  1.44075751e-02,  3.22037667e-01,\n",
       "          4.62994874e-02, -2.85171062e-01,  2.45852619e-01,\n",
       "         -5.04313111e-02, -2.56611764e-01],\n",
       "        [ 3.16289574e-01, -3.46699536e-01, -2.46106058e-01,\n",
       "          2.34564573e-01, -1.30302012e-02,  5.34648895e-02,\n",
       "         -2.14616552e-01,  9.99585092e-02,  2.26033181e-01,\n",
       "         -3.21387768e-01, -3.15356612e-01,  3.43865663e-01,\n",
       "          9.82997715e-02,  1.46370828e-02,  2.71988004e-01,\n",
       "          3.06656390e-01,  1.61941618e-01, -2.46067643e-02,\n",
       "         -1.27927065e-01,  1.70595676e-01, -1.14291310e-02,\n",
       "         -2.34527737e-01, -2.86428034e-01,  3.23547035e-01,\n",
       "         -3.92502546e-02,  1.90244526e-01,  1.45585924e-01,\n",
       "         -3.04845214e-01, -2.21854940e-01, -2.50021428e-01,\n",
       "         -2.16741174e-01,  3.33415896e-01],\n",
       "        [-2.52486587e-01, -2.99733490e-01,  4.05895114e-02,\n",
       "          1.07931346e-01, -2.36293048e-01, -4.10907090e-01,\n",
       "          3.72902423e-01, -2.04055801e-01,  3.95621628e-01,\n",
       "          2.68088549e-01,  4.62800086e-01, -2.06638891e-02,\n",
       "          1.19946085e-01,  9.25470367e-02, -3.46516788e-01,\n",
       "         -2.24529237e-01,  4.67711776e-01,  4.63986367e-01,\n",
       "          1.32565508e-02,  4.37140465e-02, -1.52988836e-01,\n",
       "          2.02262595e-01, -2.64705569e-02, -1.39452964e-01,\n",
       "          4.48021322e-01,  5.19749939e-01,  4.75976497e-01,\n",
       "          2.07197338e-01, -6.96712732e-03,  6.85037374e-02,\n",
       "          2.40279496e-01, -5.40472269e-02],\n",
       "        [-7.34552741e-03,  7.47078210e-02, -9.74196494e-02,\n",
       "          1.12318099e-02,  1.34127066e-01,  7.06951693e-02,\n",
       "          1.02478489e-01,  2.49223113e-01, -3.17002870e-02,\n",
       "          2.11598352e-01,  3.32049727e-01,  2.03382313e-01,\n",
       "          4.76100743e-02,  2.99332947e-01, -1.79431275e-01,\n",
       "          1.22945219e-01, -1.53105766e-01,  2.62440234e-01,\n",
       "         -4.39463742e-03,  3.53167802e-01,  5.56277437e-03,\n",
       "          3.04833740e-01,  2.18289241e-01, -2.43595969e-02,\n",
       "          3.01524043e-01,  2.72436172e-01, -9.83260274e-02,\n",
       "         -1.93811320e-02, -3.52314681e-01,  2.46309191e-01,\n",
       "         -1.12189762e-01,  2.74448581e-02],\n",
       "        [-3.51776898e-01, -5.26339971e-02, -2.07108855e-01,\n",
       "         -2.96921164e-01, -1.80945039e-01,  2.50432808e-02,\n",
       "          4.00922865e-01, -9.67454240e-02,  5.20864367e-01,\n",
       "          2.29287863e-01,  2.15030462e-01, -3.16012084e-01,\n",
       "         -4.57703710e-01, -4.72147584e-01,  9.20951366e-03,\n",
       "         -2.73583531e-02,  4.05351311e-01,  1.76074311e-01,\n",
       "         -1.80297405e-01, -3.35531056e-01,  1.51797861e-01,\n",
       "          3.45731437e-01, -2.29865700e-01,  2.48327360e-01,\n",
       "         -3.31325606e-02,  5.51988967e-02,  4.58623499e-01,\n",
       "          2.06248492e-01, -2.69509554e-01, -1.92560375e-01,\n",
       "          5.82839429e-01, -1.86253965e-01],\n",
       "        [ 1.24503642e-01, -2.12585166e-01, -9.85013843e-02,\n",
       "         -1.38058826e-01,  3.33898515e-01,  1.43264800e-01,\n",
       "          7.17121959e-02,  1.84719831e-01,  3.41608137e-01,\n",
       "          2.59040743e-01, -2.62400508e-02, -2.45624661e-01,\n",
       "         -2.78492033e-01,  7.99818337e-02,  2.74172157e-01,\n",
       "          2.53018469e-01,  1.92846209e-01, -2.70890176e-01,\n",
       "         -1.74442425e-01, -1.63189217e-01,  2.05009609e-01,\n",
       "          1.43383235e-01,  5.99842370e-02, -5.04114330e-02,\n",
       "          3.13453525e-01, -3.22703660e-01, -1.99016318e-01,\n",
       "          2.04250902e-01,  1.55375630e-01, -2.10974813e-01,\n",
       "         -2.29237214e-01,  2.95280486e-01],\n",
       "        [-3.53344589e-01,  1.20776683e-01,  7.95806646e-02,\n",
       "         -3.49754870e-01, -5.65653741e-02, -1.65584087e-02,\n",
       "         -1.36670336e-01,  2.74297446e-01,  2.49248594e-01,\n",
       "         -5.24273813e-02,  2.10928053e-01,  2.45831460e-01,\n",
       "          2.56358087e-02,  1.94426864e-01, -7.07321167e-02,\n",
       "         -3.04414541e-01, -1.35096908e-03,  6.96671009e-03,\n",
       "         -3.09640169e-01,  2.15161532e-01, -2.87388742e-01,\n",
       "          1.52216822e-01, -1.98885798e-02,  1.16272271e-01,\n",
       "         -2.83046782e-01,  2.10948855e-01,  2.74394423e-01,\n",
       "          2.33715385e-01,  1.28984600e-01,  2.24062413e-01,\n",
       "         -5.62427640e-02, -1.71192154e-01],\n",
       "        [-3.38692158e-01, -5.41143678e-02,  9.51024294e-02,\n",
       "          2.11508870e-02, -4.99242917e-02, -9.56063643e-02,\n",
       "          4.28766489e-01, -2.69740582e-01, -1.15985990e-01,\n",
       "         -1.01431482e-01, -9.56494734e-02, -4.27799910e-01,\n",
       "         -3.27083886e-01, -1.98581889e-01, -8.04955959e-02,\n",
       "         -5.22916913e-02,  3.93207848e-01, -7.84205720e-02,\n",
       "          1.63259789e-01,  6.42796755e-02, -1.48421898e-01,\n",
       "          2.62318611e-01,  1.19342074e-01, -2.29492784e-01,\n",
       "          5.63743055e-01, -1.05676048e-01,  1.65990353e-01,\n",
       "          4.87454206e-01, -9.33793783e-02, -4.70363796e-01,\n",
       "          2.62572885e-01, -3.35018903e-01],\n",
       "        [ 2.84972936e-01, -1.54353395e-01, -1.04767367e-01,\n",
       "         -1.01198852e-02, -2.32248768e-01, -1.35001153e-01,\n",
       "         -3.47352743e-01,  2.08577067e-01, -2.29679331e-01,\n",
       "          9.79050994e-02,  1.06138498e-01,  8.47755969e-02,\n",
       "         -7.00442791e-02, -2.02602446e-02,  2.27999419e-01,\n",
       "          2.25668460e-01, -2.43784696e-01, -2.73501098e-01,\n",
       "         -1.61883846e-01,  1.80709511e-01,  2.40083426e-01,\n",
       "          1.67855829e-01,  2.37480015e-01,  1.78542465e-01,\n",
       "         -3.43554378e-01,  1.59628719e-01,  2.03977674e-01,\n",
       "          3.44552845e-01, -2.77619779e-01,  7.02115893e-02,\n",
       "         -2.08670139e-01, -6.97839558e-02],\n",
       "        [-4.43047583e-02, -2.33087495e-01, -1.64339319e-01,\n",
       "          4.24725711e-02, -6.88132644e-03, -1.23994172e-01,\n",
       "          2.79156774e-01, -1.98847398e-01,  1.73296601e-01,\n",
       "         -1.60712510e-01,  2.60832578e-01,  3.09575111e-01,\n",
       "         -3.49161923e-01, -2.10891947e-01,  1.68581635e-01,\n",
       "         -1.38190329e-01,  1.91168785e-02, -3.26107353e-01,\n",
       "         -2.69825131e-01,  7.48335123e-02,  8.41326118e-02,\n",
       "          3.03839177e-01, -3.44306707e-01,  9.11900103e-02,\n",
       "         -1.18931741e-01, -2.69124568e-01, -7.66261816e-02,\n",
       "         -2.02165529e-01,  8.17698240e-03,  3.64701748e-02,\n",
       "          2.72725016e-01,  1.79957122e-01],\n",
       "        [ 2.59967476e-01,  2.52232760e-01, -3.08346242e-01,\n",
       "          1.17264748e-01, -1.80730313e-01,  1.21091932e-01,\n",
       "          6.86764419e-02,  4.50583398e-02,  1.56966835e-01,\n",
       "          2.72700697e-01,  5.87956905e-02,  1.81571752e-01,\n",
       "         -3.26292962e-01, -1.48574039e-01, -9.73734260e-03,\n",
       "         -2.55042881e-01,  3.81802320e-02, -3.06811512e-01,\n",
       "          1.10229760e-01, -3.09318006e-01,  2.90708572e-01,\n",
       "          6.01072311e-02,  2.58794457e-01,  1.17677361e-01,\n",
       "         -8.07930529e-02, -7.82456994e-02,  1.08923882e-01,\n",
       "         -2.56078243e-02, -1.96552664e-01, -2.44330496e-01,\n",
       "          1.36232972e-02,  1.60603374e-01],\n",
       "        [ 1.29228234e-02, -3.39894772e-01, -2.56513208e-01,\n",
       "         -5.02423346e-02, -3.01655263e-01,  8.70835781e-02,\n",
       "         -2.62162000e-01, -4.47658598e-02, -6.56996071e-02,\n",
       "          3.16387445e-01, -1.09282315e-01,  2.95306295e-01,\n",
       "         -2.15509892e-01,  7.87429512e-02,  8.93724859e-02,\n",
       "         -3.42130661e-05, -2.35774606e-01,  3.34066153e-02,\n",
       "         -1.65871784e-01,  2.24524736e-03, -1.37310222e-01,\n",
       "         -3.32542688e-01, -2.40296379e-01, -1.16168678e-01,\n",
       "          1.82253748e-01, -8.11500549e-02,  2.57529825e-01,\n",
       "          6.54662848e-02,  2.06921309e-01,  1.94271594e-01,\n",
       "          2.74691075e-01,  1.20607316e-02],\n",
       "        [-2.45931149e-02,  2.16168925e-01, -3.07068527e-01,\n",
       "         -2.81970859e-01, -6.94677755e-02,  2.26846069e-01,\n",
       "          3.51592720e-01, -1.26305848e-01,  2.22682655e-01,\n",
       "          2.07795203e-01, -2.39836667e-02,  2.28815615e-01,\n",
       "          3.00478429e-01,  2.31761828e-01,  6.84845746e-02,\n",
       "         -1.21573344e-01,  3.62118423e-01,  1.32558122e-01,\n",
       "          9.55697671e-02, -2.98582256e-01, -3.49102542e-02,\n",
       "         -2.78885700e-02, -2.42658123e-01, -5.37359007e-02,\n",
       "          3.78354579e-01,  2.36780405e-01, -1.33014023e-01,\n",
       "         -7.58196414e-02, -3.33837569e-02,  2.50591695e-01,\n",
       "          1.00614980e-01,  3.46145153e-01],\n",
       "        [-1.82539821e-02, -3.35703939e-01, -3.10418457e-01,\n",
       "         -4.13839817e-02,  1.20055974e-01, -4.21365499e-02,\n",
       "         -5.12692034e-02, -1.35175884e-02,  2.01436669e-01,\n",
       "         -2.16369271e-01,  2.05361277e-01, -9.04649198e-02,\n",
       "         -1.58982545e-01,  1.25846535e-01,  2.37918764e-01,\n",
       "          2.52440721e-01,  4.41342294e-02,  2.30922729e-01,\n",
       "         -4.05482948e-02,  4.44361567e-03, -2.28079095e-01,\n",
       "          4.44442630e-02,  1.28979385e-02,  1.65564090e-01,\n",
       "         -2.69597799e-01,  2.82735974e-01,  2.70937830e-01,\n",
       "         -2.94202358e-01, -2.43471131e-01, -3.10527980e-02,\n",
       "          2.24509150e-01, -3.40666652e-01],\n",
       "        [-3.66137326e-02, -1.92948103e-01, -1.67714283e-01,\n",
       "         -1.63602009e-01,  9.39963311e-02, -1.27887949e-01,\n",
       "          5.57450831e-01,  5.20935059e-02,  2.69783914e-01,\n",
       "          7.70993009e-02,  6.86462671e-02, -3.74299049e-01,\n",
       "         -4.73327696e-01, -4.49012071e-01,  2.37580627e-01,\n",
       "         -1.84195340e-02,  3.89761835e-01,  4.21500087e-01,\n",
       "         -2.81642616e-01, -3.16736609e-01,  8.83966088e-02,\n",
       "         -8.48907009e-02, -1.70304805e-01,  3.63521576e-02,\n",
       "          3.26491058e-01,  1.71340510e-01,  3.02392632e-01,\n",
       "          4.48549241e-01, -3.38315457e-01, -5.01481965e-02,\n",
       "          2.25645438e-01, -4.65330273e-01],\n",
       "        [-2.41161555e-01, -2.03866303e-01, -1.74641699e-01,\n",
       "         -4.13805246e-03, -2.98505962e-01,  5.82900904e-02,\n",
       "          3.71830910e-01,  2.56309122e-01,  4.75571215e-01,\n",
       "          3.72858316e-01,  1.26529723e-01, -2.33325034e-01,\n",
       "         -4.45012927e-01,  5.27213216e-02, -1.56015828e-01,\n",
       "          1.86533779e-01,  2.42020756e-01,  4.24307674e-01,\n",
       "         -2.93924361e-01,  1.63117081e-01, -3.11301082e-01,\n",
       "          3.21330070e-01, -5.39622664e-01,  2.49597579e-01,\n",
       "          4.69966143e-01, -8.41264147e-03,  1.29854545e-01,\n",
       "         -1.10940382e-01,  2.21409887e-01, -3.20531368e-01,\n",
       "          2.16449395e-01, -2.38784969e-01]], dtype=float32),\n",
       " array([ 0.        ,  0.19129185,  0.        ,  0.        ,  0.19820844,\n",
       "         0.16509704, -0.12377162, -0.01908098, -0.0874985 , -0.10525509,\n",
       "        -0.09677671,  0.200298  ,  0.22094753,  0.16016808,  0.        ,\n",
       "         0.        , -0.09836863, -0.10489105, -0.02663722,  0.        ,\n",
       "        -0.00056281, -0.07924068,  0.23163931, -0.00150063, -0.15106264,\n",
       "        -0.12997615, -0.03295687, -0.03529377,  0.        ,  0.15214558,\n",
       "        -0.05040816,  0.21656069], dtype=float32),\n",
       " array([[-0.3028408 ,  0.10765031],\n",
       "        [ 0.14157476, -0.61053276],\n",
       "        [ 0.08815917, -0.34736907],\n",
       "        [ 0.16483095, -0.34194887],\n",
       "        [ 0.7226877 , -0.12786639],\n",
       "        [ 0.6113498 , -0.4663111 ],\n",
       "        [-0.16180462,  0.26315126],\n",
       "        [-0.13043068,  0.1150819 ],\n",
       "        [-0.3807517 ,  0.29600918],\n",
       "        [-0.53430325,  0.37233034],\n",
       "        [-0.25722095,  0.26978958],\n",
       "        [ 0.7676398 , -0.59869784],\n",
       "        [ 0.46732375, -0.27143857],\n",
       "        [ 0.27070636, -0.05644391],\n",
       "        [ 0.03028211, -0.22487189],\n",
       "        [ 0.02726671, -0.29540834],\n",
       "        [-0.37435868,  0.14072926],\n",
       "        [-0.36700276,  0.32920778],\n",
       "        [-0.34736252,  0.00295176],\n",
       "        [ 0.08526525, -0.07036379],\n",
       "        [ 0.02533339,  0.11319116],\n",
       "        [-0.40156585, -0.17370741],\n",
       "        [ 0.45768076, -0.28036532],\n",
       "        [-0.20226286,  0.05095496],\n",
       "        [ 0.10013375,  0.497827  ],\n",
       "        [ 0.0024695 ,  0.3872898 ],\n",
       "        [-0.21671388,  0.4103309 ],\n",
       "        [-0.6118391 ,  0.38492522],\n",
       "        [-0.25990278, -0.35260373],\n",
       "        [ 0.28547537, -0.40263763],\n",
       "        [-0.30777597,  0.37498036],\n",
       "        [ 0.53188425, -0.5415132 ]], dtype=float32),\n",
       " array([ 0.13897736, -0.1389774 ], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
